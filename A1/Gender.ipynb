{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples 3955\n",
      "Number of test examples 521\n",
      "Number of validation examples 524\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "directory = \"/Users/devan/Desktop/AMLS_20-21_SN12345678/Datasets/celeba/img/\"\n",
    "train = \"/Users/devan/Desktop/AMLS_20-21_SN12345678/A1/data/train/\"\n",
    "test = \"/Users/devan/Desktop/AMLS_20-21_SN12345678/A1/data/test/\"\n",
    "validation = \"/Users/devan/Desktop/AMLS_20-21_SN12345678/A1/data/validation/\"\n",
    "\n",
    "os.makedirs(train + \"male/\")\n",
    "os.makedirs(train + \"female/\")\n",
    "os.makedirs(test + \"male/\")\n",
    "os.makedirs(test + \"female/\")\n",
    "os.makedirs(validation + \"male/\")\n",
    "os.makedirs(validation + \"female/\")\n",
    "\n",
    "test_examples = train_examples = validation_examples = 0\n",
    "\n",
    "for line in open(\"/Users/devan/Desktop/AMLS_20-21_SN12345678/Datasets/celeba/labels.csv\").readlines()[1:]:\n",
    "    split_line = line.split(\",\")\n",
    "    img_file = split_line[1]\n",
    "    male_female = split_line[2]\n",
    "    \n",
    "    random_num = random.random()\n",
    "\n",
    "    if random_num < 0.8:\n",
    "        location = train\n",
    "        train_examples += 1\n",
    "\n",
    "    elif random_num < 0.9:\n",
    "        location = validation\n",
    "        validation_examples += 1\n",
    "\n",
    "    else:\n",
    "        location = test\n",
    "        test_examples += 1\n",
    "\n",
    "    if int(float(male_female)) == -1:\n",
    "        shutil.copy(\n",
    "            \"/Users/devan/Desktop/AMLS_20-21_SN12345678/Datasets/celeba/img/\" + img_file,\n",
    "            location + \"female/\" + img_file + \".jpg\",\n",
    "        )\n",
    "\n",
    "    elif int(float(male_female)) == 1:\n",
    "        shutil.copy(\n",
    "            \"/Users/devan/Desktop/AMLS_20-21_SN12345678/Datasets/celeba/img/\" + img_file,\n",
    "            location + \"male/\" + img_file + \".jpg\",\n",
    "        )\n",
    "\n",
    "print(f\"Number of training examples {train_examples}\")\n",
    "print(f\"Number of test examples {test_examples}\")\n",
    "print(f\"Number of validation examples {validation_examples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import roc_curve\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = 3955\n",
    "test_examples = 521\n",
    "validation_examples = 524\n",
    "img_height = img_width = 55\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(55,55,1)), #We dont flatten the input since we are using convolutional neural networks\n",
    "        layers.Conv2D(96, 5, strides = 1 , padding='same', activation = 'relu'),\n",
    "        layers.MaxPooling2D(pool_size=(3,3), strides = 2,padding='same'),\n",
    "        layers.Conv2D(256, 3, strides = 1 , padding='same', activation = 'relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2,2), strides = 2,padding='same'),\n",
    "        layers.Conv2D(384, 3, strides = 1 , padding='same', activation = 'relu'),\n",
    "        layers.Conv2D(256, 3, strides = 1 , padding='same', activation = 'relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3955 images belonging to 2 classes.\n",
      "Found 524 images belonging to 2 classes.\n",
      "Found 521 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1/255,\n",
    "    rotation_range = 15,\n",
    "    zoom_range = (0.95,0.95),\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    data_format = \"channels_last\",\n",
    "    dtype = tf.float32,\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255, dtype = tf.float32)\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255, dtype = tf.float32)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "\"/Users/devan/Desktop/AMLS_20-21_SN12345678/A1/data/train/\",\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size,\n",
    "color_mode = \"grayscale\",\n",
    "class_mode = \"binary\",   \n",
    "shuffle = True,\n",
    "seed = 123,\n",
    ")\n",
    "\n",
    "validation_gen = validation_datagen.flow_from_directory(\n",
    "\"/Users/devan/Desktop/AMLS_20-21_SN12345678/A1/data/validation/\",\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size,\n",
    "color_mode = \"grayscale\",\n",
    "class_mode = \"binary\",   \n",
    "shuffle = True,\n",
    "seed = 123,\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "\"/Users/devan/Desktop/AMLS_20-21_SN12345678/A1/data/test/\",\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size,\n",
    "color_mode = \"grayscale\",\n",
    "class_mode = \"binary\",   \n",
    "shuffle = True,\n",
    "seed = 123,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits = False),\n",
    "    optimizer = keras.optimizers.Adam(lr = 3e-4),\n",
    "    metrics = [\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "123/123 - 129s - loss: 0.6521 - accuracy: 0.6069 - val_loss: 0.6018 - val_accuracy: 0.6777\n",
      "Epoch 2/10\n",
      "123/123 - 128s - loss: 0.4863 - accuracy: 0.7685 - val_loss: 0.4172 - val_accuracy: 0.8086\n",
      "Epoch 3/10\n",
      "123/123 - 132s - loss: 0.3987 - accuracy: 0.8218 - val_loss: 0.3581 - val_accuracy: 0.8457\n",
      "Epoch 4/10\n",
      "123/123 - 131s - loss: 0.3623 - accuracy: 0.8430 - val_loss: 0.3633 - val_accuracy: 0.8359\n",
      "Epoch 5/10\n",
      "123/123 - 134s - loss: 0.3438 - accuracy: 0.8481 - val_loss: 0.3665 - val_accuracy: 0.8281\n",
      "Epoch 6/10\n",
      "123/123 - 135s - loss: 0.3313 - accuracy: 0.8575 - val_loss: 0.3209 - val_accuracy: 0.8652\n",
      "Epoch 7/10\n",
      "123/123 - 129s - loss: 0.3189 - accuracy: 0.8649 - val_loss: 0.2828 - val_accuracy: 0.8848\n",
      "Epoch 8/10\n",
      "123/123 - 130s - loss: 0.2899 - accuracy: 0.8759 - val_loss: 0.2906 - val_accuracy: 0.8730\n",
      "Epoch 9/10\n",
      "123/123 - 128s - loss: 0.2780 - accuracy: 0.8794 - val_loss: 0.3151 - val_accuracy: 0.8770\n",
      "Epoch 10/10\n",
      "123/123 - 128s - loss: 0.2782 - accuracy: 0.8858 - val_loss: 0.2931 - val_accuracy: 0.8672\n"
     ]
    }
   ],
   "source": [
    "  history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=10,\n",
    "    batch_size = 10,\n",
    "    verbose=2,\n",
    "    steps_per_epoch=train_examples // batch_size,\n",
    "    validation_data=validation_gen,\n",
    "    validation_steps=validation_examples // batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(labels, data):\n",
    "    predictions = model.predict(data)\n",
    "    fp, tp, _ = roc_curve(labels,predictions)\n",
    "    \n",
    "    plt.plot(100*fp, 100*tp)\n",
    "    plt.xlabel(\"False\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.grid()\n",
    "    plt.show\n",
    "    \n",
    "test_labels = np.array([])\n",
    "num_batches = 0\n",
    "\n",
    "for _, y in test_gen:\n",
    "    test_labels = np.append(test_labels, y)\n",
    "    num_batches += 1\n",
    "    if num_batches == math.ceil(test_examples / batch_size):\n",
    "        break\n",
    "        \n",
    "plot_roc(test_labels, test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 - 4s - loss: 0.2411 - accuracy: 0.9155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24114267528057098, 0.9155470132827759]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_gen, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Sequential in module tensorflow.python.keras.engine.sequential object:\n",
      "\n",
      "class Sequential(tensorflow.python.keras.engine.functional.Functional)\n",
      " |  Sequential(*args, **kwargs)\n",
      " |  \n",
      " |  `Sequential` groups a linear stack of layers into a `tf.keras.Model`.\n",
      " |  \n",
      " |  `Sequential` provides training and inference features on this model.\n",
      " |  \n",
      " |  Examples:\n",
      " |  \n",
      " |  >>> # Optionally, the first layer can receive an `input_shape` argument:\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
      " |  >>> # Afterwards, we do automatic shape inference:\n",
      " |  >>> model.add(tf.keras.layers.Dense(4))\n",
      " |  \n",
      " |  >>> # This is identical to the following:\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.Input(shape=(16,)))\n",
      " |  >>> model.add(tf.keras.layers.Dense(8))\n",
      " |  \n",
      " |  >>> # Note that you can also omit the `input_shape` argument.\n",
      " |  >>> # In that case the model doesn't have any weights until the first call\n",
      " |  >>> # to a training/evaluation method (since it isn't yet built):\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Dense(8))\n",
      " |  >>> model.add(tf.keras.layers.Dense(4))\n",
      " |  >>> # model.weights not created yet\n",
      " |  \n",
      " |  >>> # Whereas if you specify the input shape, the model gets built\n",
      " |  >>> # continuously as you are adding layers:\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
      " |  >>> model.add(tf.keras.layers.Dense(4))\n",
      " |  >>> len(model.weights)\n",
      " |  4\n",
      " |  \n",
      " |  >>> # When using the delayed-build pattern (no input shape specified), you can\n",
      " |  >>> # choose to manually build your model by calling\n",
      " |  >>> # `build(batch_input_shape)`:\n",
      " |  >>> model = tf.keras.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.Dense(8))\n",
      " |  >>> model.add(tf.keras.layers.Dense(4))\n",
      " |  >>> model.build((None, 16))\n",
      " |  >>> len(model.weights)\n",
      " |  4\n",
      " |  \n",
      " |  ```python\n",
      " |  # Note that when using the delayed-build pattern (no input shape specified),\n",
      " |  # the model gets built the first time you call `fit`, `eval`, or `predict`,\n",
      " |  # or the first time you call the model on some input data.\n",
      " |  model = tf.keras.Sequential()\n",
      " |  model.add(tf.keras.layers.Dense(8))\n",
      " |  model.add(tf.keras.layers.Dense(1))\n",
      " |  model.compile(optimizer='sgd', loss='mse')\n",
      " |  # This builds the model for the first time:\n",
      " |  model.fit(x, y, batch_size=32, epochs=10)\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Sequential\n",
      " |      tensorflow.python.keras.engine.functional.Functional\n",
      " |      tensorflow.python.keras.engine.training.Model\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      tensorflow.python.keras.utils.version_utils.LayerVersionSelector\n",
      " |      tensorflow.python.keras.utils.version_utils.ModelVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, layers=None, name=None)\n",
      " |      Creates a `Sequential` model instance.\n",
      " |      \n",
      " |      Args:\n",
      " |        layers: Optional list of layers to add to the model.\n",
      " |        name: Optional name for the model.\n",
      " |  \n",
      " |  add(self, layer)\n",
      " |      Adds a layer instance on top of the layer stack.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          layer: layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: If `layer` is not a layer instance.\n",
      " |          ValueError: In case the `layer` argument does not\n",
      " |              know its input shape.\n",
      " |          ValueError: In case the `layer` argument has\n",
      " |              multiple output tensors, or is already connected\n",
      " |              somewhere else (forbidden in `Sequential` models).\n",
      " |  \n",
      " |  build(self, input_shape=None)\n",
      " |      Builds the model based on input shapes received.\n",
      " |      \n",
      " |      This is to be used for subclassed models, which do not know at instantiation\n",
      " |      time what their inputs look like.\n",
      " |      \n",
      " |      This method only exists for users who want to call `model.build()` in a\n",
      " |      standalone way (as a substitute for calling the model on real data to\n",
      " |      build it). It will never be called by the framework (and thus it will\n",
      " |      never throw unexpected errors in an unrelated workflow).\n",
      " |      \n",
      " |      Args:\n",
      " |       input_shape: Single tuple, TensorShape, or list of shapes, where shapes\n",
      " |           are tuples, integers, or TensorShapes.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError:\n",
      " |          1. In case of invalid user-provided data (not of type tuple,\n",
      " |             list, or TensorShape).\n",
      " |          2. If the model requires call arguments that are agnostic\n",
      " |             to the input shapes (positional or kwarg in call signature).\n",
      " |          3. If not all layers were properly built.\n",
      " |          4. If float type inputs are not supported within the layers.\n",
      " |      \n",
      " |        In each of these cases, the user should build their model by calling it\n",
      " |        on real tensor data.\n",
      " |  \n",
      " |  call(self, inputs, training=None, mask=None)\n",
      " |      Calls the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          training: Boolean or boolean scalar tensor, indicating whether to run\n",
      " |            the `Network` in training mode or inference mode.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  pop(self)\n",
      " |      Removes the last layer in the model.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: if there are no layers in the model.\n",
      " |  \n",
      " |  predict_classes(self, x, batch_size=32, verbose=0)\n",
      " |      Generate class predictions for the input samples. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed after 2021-01-01.\n",
      " |      Instructions for updating:\n",
      " |      Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: integer.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A numpy array of class predictions.\n",
      " |  \n",
      " |  predict_proba(self, x, batch_size=32, verbose=0)\n",
      " |      Generates class probability predictions for the input samples. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed after 2021-01-01.\n",
      " |      Instructions for updating:\n",
      " |      Please use `model.predict()` instead.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: integer.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A Numpy array of probability predictions.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Instantiates a Model from its config (output of `get_config()`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: Model config dictionary.\n",
      " |          custom_objects: Optional dictionary mapping names\n",
      " |              (strings) to custom classes or functions to be\n",
      " |              considered during deserialization.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A model instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of improperly formatted config dict.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
      " |      the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
      " |      of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
      " |      error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  layers\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.keras.engine.functional.Functional:\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          optimizer: String (name of optimizer) or optimizer instance. See\n",
      " |            `tf.keras.optimizers`.\n",
      " |          loss: String (name of objective function), objective function or\n",
      " |            `tf.keras.losses.Loss` instance. See `tf.keras.losses`. An objective\n",
      " |            function is any callable with the signature `loss = fn(y_true,\n",
      " |            y_pred)`, where y_true = ground truth values with shape =\n",
      " |            `[batch_size, d0, .. dN]`, except sparse loss functions such as sparse\n",
      " |            categorical crossentropy where shape = `[batch_size, d0, .. dN-1]`.\n",
      " |            y_pred = predicted values with shape = `[batch_size, d0, .. dN]`. It\n",
      " |            returns a weighted loss float tensor. If a custom `Loss` instance is\n",
      " |            used and reduction is set to NONE, return value has the shape\n",
      " |            [batch_size, d0, .. dN-1] ie. per-sample or per-timestep loss values;\n",
      " |            otherwise, it is a scalar. If the model has multiple outputs, you can\n",
      " |            use a different loss on each output by passing a dictionary or a list\n",
      " |            of losses. The loss value that will be minimized by the model will\n",
      " |            then be the sum of all individual losses.\n",
      " |          metrics: List of metrics to be evaluated by the model during training\n",
      " |            and testing. Each of this can be a string (name of a built-in\n",
      " |            function), function or a `tf.keras.metrics.Metric` instance. See\n",
      " |            `tf.keras.metrics`. Typically you will use `metrics=['accuracy']`. A\n",
      " |            function is any callable with the signature `result = fn(y_true,\n",
      " |            y_pred)`. To specify different metrics for different outputs of a\n",
      " |            multi-output model, you could also pass a dictionary, such as\n",
      " |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
      " |                You can also pass a list (len = len(outputs)) of lists of metrics\n",
      " |                such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
      " |                `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
      " |                strings 'accuracy' or 'acc', we convert this to one of\n",
      " |                `tf.keras.metrics.BinaryAccuracy`,\n",
      " |                `tf.keras.metrics.CategoricalAccuracy`,\n",
      " |                `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n",
      " |                function used and the model output shape. We do a similar\n",
      " |                conversion for the strings 'crossentropy' and 'ce' as well.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar coefficients\n",
      " |            (Python floats) to weight the loss contributions of different model\n",
      " |            outputs. The loss value that will be minimized by the model will then\n",
      " |            be the *weighted sum* of all individual losses, weighted by the\n",
      " |            `loss_weights` coefficients.\n",
      " |              If a list, it is expected to have a 1:1 mapping to the model's\n",
      " |                outputs. If a dict, it is expected to map output names (strings)\n",
      " |                to scalar coefficients.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted by\n",
      " |            sample_weight or class_weight during training and testing.\n",
      " |          run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
      " |            logic will not be wrapped in a `tf.function`. Recommended to leave\n",
      " |            this as `None` unless your `Model` cannot be run inside a\n",
      " |            `tf.function`.\n",
      " |          **kwargs: Any additional arguments. Supported arguments:\n",
      " |              - `experimental_steps_per_execution`: Int. The number of batches to\n",
      " |                run during each `tf.function` call. Running multiple batches\n",
      " |                inside a single `tf.function` call can greatly improve performance\n",
      " |                on TPUs or small models with a large Python overhead. Note that if\n",
      " |                this value is set to `N`, `Callback.on_batch` methods will only be\n",
      " |                called every `N` batches. This currently defaults to `1`. At most,\n",
      " |                one full epoch will be run each execution. If a number larger than\n",
      " |                the size of the epoch is passed, the execution will be truncated\n",
      " |                to the size of the epoch.\n",
      " |              - `sample_weight_mode` for backward compatibility.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid arguments for\n",
      " |              `optimizer`, `loss` or `metrics`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches (see the `batch_size` arg.)\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
      " |            `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
      " |            should not be specified (since targets will be obtained from the\n",
      " |            iterator/dataset).\n",
      " |          batch_size: Integer or `None`. Number of samples per batch of\n",
      " |            computation. If unspecified, `batch_size` will default to 32. Do not\n",
      " |            specify the `batch_size` if your data is in the form of a dataset,\n",
      " |            generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |            batches).\n",
      " |          verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
      " |          sample_weight: Optional Numpy array of weights for the test samples,\n",
      " |            used for weighting the loss function. You can either pass a flat (1D)\n",
      " |            Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples), or in the case of\n",
      " |                temporal data, you can pass a 2D array with shape `(samples,\n",
      " |                sequence_length)`, to apply a different weight to every timestep\n",
      " |                of every sample. This argument is not supported when `x` is a\n",
      " |                dataset, instead pass sample weights as the third element of `x`.\n",
      " |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
      " |            before declaring the evaluation round finished. Ignored with the\n",
      " |            default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
      " |            None, 'evaluate' will run until the dataset is exhausted. This\n",
      " |            argument is not supported with array inputs.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
      " |            callbacks to apply during evaluation. See\n",
      " |            [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |            input only. Maximum size for the generator queue. If unspecified,\n",
      " |            `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |            only. Maximum number of processes to spin up when using process-based\n",
      " |            threading. If unspecified, `workers` will default to 1. If 0, will\n",
      " |            execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |            threading. If unspecified, `use_multiprocessing` will default to\n",
      " |            `False`. Note that because this implementation relies on\n",
      " |            multiprocessing, you should not pass non-picklable arguments to the\n",
      " |            generator as they can't be passed easily to children processes.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.evaluate` is wrapped in `tf.function`.\n",
      " |          ValueError: in case of invalid arguments.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Evaluates the model on a data generator. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use Model.evaluate, which supports generators.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.evaluate` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample_weights)`.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given below.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
      " |            or `keras.utils.Sequence` instance, `y` should\n",
      " |            not be specified (since targets will be obtained from `x`).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |              Note that the progress bar is not particularly useful when\n",
      " |              logged to a file, so verbose=2 is recommended when not running\n",
      " |              interactively (eg, in a production environment).\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See `tf.keras.callbacks`.\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling. This argument is\n",
      " |              not supported when `x` is a dataset, generator or\n",
      " |             `keras.utils.Sequence` instance.\n",
      " |          validation_data: Data on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data. Thus, note the fact\n",
      " |              that the validation loss of data provided using `validation_split`\n",
      " |              or `validation_data` is not affected by regularization layers like\n",
      " |              noise and dropuout.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |              `validation_data` could be:\n",
      " |                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      " |                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      " |                - dataset\n",
      " |              For the first two cases, `batch_size` must be provided.\n",
      " |              For the last case, `validation_steps` could be provided.\n",
      " |              Note that `validation_data` does not support all the data types that\n",
      " |              are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch'). This argument is ignored\n",
      " |              when `x` is a generator. 'batch' is a special option for dealing\n",
      " |              with the limitations of HDF5 data; it shuffles in batch-sized\n",
      " |              chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample. This\n",
      " |              argument is not supported when `x` is a dataset, generator, or\n",
      " |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
      " |              as the third element of `x`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined. If x is a\n",
      " |              `tf.data` dataset, and 'steps_per_epoch'\n",
      " |              is None, the epoch will run until the input dataset is exhausted.\n",
      " |              When passing an infinitely repeating dataset, you must specify the\n",
      " |              `steps_per_epoch` argument. This argument is not supported with\n",
      " |              array inputs.\n",
      " |          validation_steps: Only relevant if `validation_data` is provided and\n",
      " |              is a `tf.data` dataset. Total number of steps (batches of\n",
      " |              samples) to draw before stopping when performing validation\n",
      " |              at the end of every epoch. If 'validation_steps' is None, validation\n",
      " |              will run until the `validation_data` dataset is exhausted. In the\n",
      " |              case of an infinitely repeated dataset, it will run into an\n",
      " |              infinite loop. If 'validation_steps' is specified and only part of\n",
      " |              the dataset will be consumed, the evaluation will start from the\n",
      " |              beginning of the dataset at each epoch. This ensures that the same\n",
      " |              validation samples are used every time.\n",
      " |          validation_batch_size: Integer or `None`.\n",
      " |              Number of samples per validation batch.\n",
      " |              If unspecified, will default to `batch_size`.\n",
      " |              Do not specify the `validation_batch_size` if your data is in the\n",
      " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          validation_freq: Only relevant if validation data is provided. Integer\n",
      " |              or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
      " |              If an integer, specifies how many training epochs to run before a\n",
      " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
      " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up\n",
      " |              when using process-based threading. If unspecified, `workers`\n",
      " |              will default to 1. If 0, will execute the generator on the main\n",
      " |              thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      Unpacking behavior for iterator-like inputs:\n",
      " |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
      " |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
      " |        yield not only features (x) but optionally targets (y) and sample weights.\n",
      " |        Keras requires that the output of such iterator-likes be unambiguous. The\n",
      " |        iterator should return a tuple of length 1, 2, or 3, where the optional\n",
      " |        second and third elements will be used for y and sample_weight\n",
      " |        respectively. Any other type provided will be wrapped in a length one\n",
      " |        tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
      " |        should still adhere to the top-level tuple structure.\n",
      " |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      " |        features, targets, and weights from the keys of a single dict.\n",
      " |          A notable unsupported data type is the namedtuple. The reason is that\n",
      " |        it behaves like both an ordered datatype (tuple) and a mapping\n",
      " |        datatype (dict). So given a namedtuple of the form:\n",
      " |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      " |        it is ambiguous whether to reverse the order of the elements when\n",
      " |        interpreting the value. Even worse is a tuple of the form:\n",
      " |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      " |        where it is unclear if the tuple was intended to be unpacked into x, y,\n",
      " |        and sample_weight or passed through as a single element to `x`. As a\n",
      " |        result the data processing code will simply raise a ValueError if it\n",
      " |        encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: 1. If the model was never compiled or,\n",
      " |          2. If `model.fit` is  wrapped in `tf.function`.\n",
      " |      \n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Fits the model on data yielded batch-by-batch by a Python generator. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use Model.fit, which supports generators.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.fit` now supports generators, so there is no longer any need to use\n",
      " |        this endpoint.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None)\n",
      " |      Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
      " |      \n",
      " |      If `by_name` is False weights are loaded based on the network's\n",
      " |      topology. This means the architecture should be the same as when the weights\n",
      " |      were saved.  Note that layers that don't have weights are not taken into\n",
      " |      account in the topological ordering, so adding or removing layers is fine as\n",
      " |      long as they don't have weights.\n",
      " |      \n",
      " |      If `by_name` is True, weights are loaded into layers only if they share the\n",
      " |      same name. This is useful for fine-tuning or transfer-learning models where\n",
      " |      some of the layers have changed.\n",
      " |      \n",
      " |      Only topological loading (`by_name=False`) is supported when loading weights\n",
      " |      from the TensorFlow format. Note that topological loading differs slightly\n",
      " |      between TensorFlow and HDF5 formats for user-defined classes inheriting from\n",
      " |      `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the\n",
      " |      TensorFlow format loads based on the object-local names of attributes to\n",
      " |      which layers are assigned in the `Model`'s constructor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, path to the weights file to load. For weight files in\n",
      " |              TensorFlow format, this is the file prefix (the same as was passed\n",
      " |              to `save_weights`).\n",
      " |          by_name: Boolean, whether to load weights by name or by topological\n",
      " |              order. Only topological loading is supported for weight files in\n",
      " |              TensorFlow format.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers where there is\n",
      " |              a mismatch in the number of weights, or a mismatch in the shape of\n",
      " |              the weight (only valid when `by_name=True`).\n",
      " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
      " |              options for loading weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          When loading a weight file in TensorFlow format, returns the same status\n",
      " |          object as `tf.train.Checkpoint.restore`. When graph building, restore\n",
      " |          ops are run automatically as soon as the network is built (on first call\n",
      " |          for user-defined classes inheriting from `Model`, immediately if it is\n",
      " |          already built).\n",
      " |      \n",
      " |          When loading weights in HDF5 format, returns `None`.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available and the weight file is in HDF5\n",
      " |              format.\n",
      " |          ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
      " |            `False`.\n",
      " |  \n",
      " |  make_predict_function(self)\n",
      " |      Creates a function that executes one step of inference.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.predict` and `Model.predict_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.predict_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.predict` or\n",
      " |      `Model.predict_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return the outputs of the `Model`.\n",
      " |  \n",
      " |  make_test_function(self)\n",
      " |      Creates a function that executes one step of evaluation.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.evaluate` and `Model.test_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
      " |      logic to `Model.test_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.evaluate` or\n",
      " |      `Model.test_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_test_batch_end`.\n",
      " |  \n",
      " |  make_train_function(self)\n",
      " |      Creates a function that executes one step of training.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
      " |      \n",
      " |      Typically, this method directly controls `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
      " |      logic to `Model.train_step`.\n",
      " |      \n",
      " |      This function is cached the first time `Model.fit` or\n",
      " |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
      " |      `Model.compile` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Function. The function created by this method should accept a\n",
      " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
      " |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches. This method is designed for performance in\n",
      " |      large scale inputs. For small amount of inputs that fit in one batch,\n",
      " |      directly using `__call__` is recommended for faster execution, e.g.,\n",
      " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
      " |      `tf.keras.layers.BatchNormalization` that behaves differently during\n",
      " |      inference. Also, note the fact that test loss is not affected by\n",
      " |      regularization layers like noise and dropout.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input samples. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A `tf.data` dataset.\n",
      " |            - A generator or `keras.utils.Sequence` instance.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per batch.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
      " |              (since they generate batches).\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
      " |              dataset and `steps` is None, `predict` will\n",
      " |              run until the input dataset is exhausted.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during prediction.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1. If 0, will execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`. Note that Model.predict uses the same interpretation rules as\n",
      " |      `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all\n",
      " |      three methods.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.predict` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use Model.predict, which supports generators.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.predict` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
      " |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
      " |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.predict_on_batch` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of mismatch between given number of inputs and\n",
      " |            expectations of the model.\n",
      " |  \n",
      " |  predict_step(self, data)\n",
      " |      The logic for one inference step.\n",
      " |      \n",
      " |      This method can be overridden to support custom inference logic.\n",
      " |      This method is called by `Model.make_predict_function`.\n",
      " |      \n",
      " |      This method should contain the mathemetical logic for one step of inference.\n",
      " |      This typically includes the forward pass.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_predict_function`, which can also be overridden.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The result of one inference step, typically the output of calling the\n",
      " |        `Model` on data.\n",
      " |  \n",
      " |  reset_metrics(self)\n",
      " |      Resets the state of all the metrics in the model.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> _ = model.fit(x, y, verbose=0)\n",
      " |      >>> assert all(float(m.result()) for m in model.metrics)\n",
      " |      \n",
      " |      >>> model.reset_metrics()\n",
      " |      >>> assert all(float(m.result()) == 0 for m in model.metrics)\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None)\n",
      " |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
      " |      \n",
      " |      The savefile includes:\n",
      " |      \n",
      " |      - The model architecture, allowing to re-instantiate the model.\n",
      " |      - The model weights.\n",
      " |      - The state of the optimizer, allowing to resume training\n",
      " |          exactly where you left off.\n",
      " |      \n",
      " |      This allows you to save the entirety of the state of a model\n",
      " |      in a single file.\n",
      " |      \n",
      " |      Saved models can be reinstantiated via `keras.models.load_model`.\n",
      " |      The model returned by `load_model` is a compiled model ready to be used\n",
      " |      (unless the saved model was never compiled in the first place).\n",
      " |      \n",
      " |      Models built with the Sequential and Functional API can be saved to both the\n",
      " |      HDF5 and SavedModel formats. Subclassed models can only be saved with the\n",
      " |      SavedModel format.\n",
      " |      \n",
      " |      Note that the model weights may have different scoped names after being\n",
      " |      loaded. Scoped names include the model/layer names, such as\n",
      " |      `\"dense_1/kernel:0\"`. It is recommended that you use the layer properties to\n",
      " |       access specific variables, e.g. `model.get_layer(\"dense_1\").kernel`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, PathLike, path to SavedModel or H5 file to save the\n",
      " |              model.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |          save_format: Either `'tf'` or `'h5'`, indicating whether to save the\n",
      " |              model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,\n",
      " |              and 'h5' in TF 1.X.\n",
      " |          signatures: Signatures to save with the SavedModel. Applicable to the\n",
      " |              'tf' format only. Please see the `signatures` argument in\n",
      " |              `tf.saved_model.save` for details.\n",
      " |          options: Optional `tf.saved_model.SaveOptions` object that specifies\n",
      " |              options for saving to SavedModel.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True, save_format=None, options=None)\n",
      " |      Saves all layer weights.\n",
      " |      \n",
      " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
      " |      argument.\n",
      " |      \n",
      " |      When saving in HDF5 format, the weight file has:\n",
      " |        - `layer_names` (attribute), a list of strings\n",
      " |            (ordered names of model layers).\n",
      " |        - For every layer, a `group` named `layer.name`\n",
      " |            - For every such layer group, a group attribute `weight_names`,\n",
      " |                a list of strings\n",
      " |                (ordered names of weights tensor of the layer).\n",
      " |            - For every weight in the layer, a dataset\n",
      " |                storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      When saving in TensorFlow format, all objects referenced by the network are\n",
      " |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
      " |      instances or `Optimizer` instances assigned to object attributes. For\n",
      " |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
      " |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
      " |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
      " |      `Layer` instances must be assigned to object attributes, typically in the\n",
      " |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
      " |      `tf.keras.Model` for details.\n",
      " |      \n",
      " |      While the formats are the same, do not mix `save_weights` and\n",
      " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
      " |      loaded using `Model.load_weights`. Checkpoints saved using\n",
      " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
      " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
      " |      `save_weights` for training checkpoints.\n",
      " |      \n",
      " |      The TensorFlow format matches objects and variables by starting at a root\n",
      " |      object, `self` for `save_weights`, and greedily matching attribute\n",
      " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
      " |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
      " |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
      " |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
      " |      the `Model`'s variables. See the [guide to training\n",
      " |      checkpoints](https://www.tensorflow.org/guide/checkpoint) for details\n",
      " |      on the TensorFlow format.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String or PathLike, path to the file to save the weights to.\n",
      " |              When saving in TensorFlow format, this is the prefix used for\n",
      " |              checkpoint files (multiple files are generated). Note that the '.h5'\n",
      " |              suffix causes weights to be saved in HDF5 format.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
      " |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
      " |              `None` defaults to 'tf'.\n",
      " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
      " |              options for saving weights.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available when attempting to save in HDF5\n",
      " |              format.\n",
      " |          ValueError: For invalid/unknown format arguments.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use. Defaults to `print`.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
      " |            of arrays (in case the model has multiple inputs). - A TensorFlow\n",
      " |            tensor, or a list of tensors (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors, if\n",
      " |            the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If `model.test_on_batch` is wrapped in `tf.function`.\n",
      " |          ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  test_step(self, data)\n",
      " |      The logic for one evaluation step.\n",
      " |      \n",
      " |      This method can be overridden to support custom evaluation logic.\n",
      " |      This method is called by `Model.make_test_function`.\n",
      " |      \n",
      " |      This function should contain the mathemetical logic for one step of\n",
      " |      evaluation.\n",
      " |      This typically includes the forward pass, loss calculation, and metrics\n",
      " |      updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_test_function`, which can also be overridden.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A YAML string.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: if yaml module is not found.\n",
      " |  \n",
      " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |                if the model has named inputs.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
      " |            weight (float) to apply to the model's loss for the samples from this\n",
      " |            class during training. This can be useful to tell the model to \"pay\n",
      " |            more attention\" to samples from an under-represented class.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
      " |            with each key being the name of the metric. If `False`, they are\n",
      " |            returned as a list.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If `model.train_on_batch` is wrapped in `tf.function`.\n",
      " |        ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  train_step(self, data)\n",
      " |      The logic for one training step.\n",
      " |      \n",
      " |      This method can be overridden to support custom training logic.\n",
      " |      This method is called by `Model.make_train_function`.\n",
      " |      \n",
      " |      This method should contain the mathemetical logic for one step of training.\n",
      " |      This typically includes the forward pass, loss calculation, backpropagation,\n",
      " |      and metric updates.\n",
      " |      \n",
      " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
      " |      `tf.distribute.Strategy` settings), should be left to\n",
      " |      `Model.make_train_function`, which can also be overridden.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        data: A nested structure of `Tensor`s.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `dict` containing values that will be passed to\n",
      " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
      " |        values of the `Model`'s metrics are returned. Example:\n",
      " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  distribute_strategy\n",
      " |      The `tf.distribute.Strategy` this model was created under.\n",
      " |  \n",
      " |  metrics\n",
      " |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
      " |      \n",
      " |      Note: Metrics passed to `compile()` are available only after a `keras.Model`\n",
      " |      has been trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> model.fit(x, y)\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.add_metric(\n",
      " |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> model.fit(x, (y, y))\n",
      " |      >>> [m.name for m in model.metrics]\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc', 'mean']\n",
      " |  \n",
      " |  metrics_names\n",
      " |      Returns the model's display labels for all outputs.\n",
      " |      \n",
      " |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
      " |      trained/evaluated on actual data.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
      " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
      " |      >>> model.metrics_names\n",
      " |      []\n",
      " |      \n",
      " |      >>> x = np.random.random((2, 3))\n",
      " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
      " |      >>> model.fit(x, y)\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'mae']\n",
      " |      \n",
      " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
      " |      >>> output_1 = d(inputs)\n",
      " |      >>> output_2 = d(inputs)\n",
      " |      >>> model = tf.keras.models.Model(\n",
      " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
      " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
      " |      >>> model.fit(x, (y, y))\n",
      " |      >>> model.metrics_names\n",
      " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
      " |      'out_1_acc']\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are expected\n",
      " |      to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  state_updates\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      " |      \n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  run_eagerly\n",
      " |      Settable attribute indicating whether the model should run eagerly.\n",
      " |      \n",
      " |      Running eagerly means that your model will be run step by step,\n",
      " |      like Python code. Your model might run slower, but it should become easier\n",
      " |      for you to debug it by stepping into individual layer calls.\n",
      " |      \n",
      " |      By default, we will attempt to compile your model to a static graph to\n",
      " |      deliver the best execution performance.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Boolean, whether the model should run eagerly.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |            inputs - Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = metrics_module.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(x))\n",
      " |          self.add_metric(math_ops.reduce_sum(x), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This is\n",
      " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result of\n",
      " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
      " |          using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.losses` instead.\n",
      " |      \n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.updates` instead.\n",
      " |      \n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a Dense layer returns a list of two values-- per-output\n",
      " |      weights and the bias value. These can be used to set the weights of another\n",
      " |      Dense layer:\n",
      " |      \n",
      " |      >>> a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b.set_weights(a.get_weights())\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  dtype\n",
      " |      Dtype used by the weights of the layer, set in the constructor.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor 'Abs:0' shape=() dtype=float32>]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  updates\n",
      " |      DEPRECATED FUNCTION\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend((['Train', 'Test']), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend((['Train', 'Test']), loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

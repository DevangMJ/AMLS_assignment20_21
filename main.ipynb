{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "directory = \"/Users/devan/Desktop/AMLS_20-21_SN12345678/Datasets/celeba/img/\" #  the paths are fixed, and will not work on a  \n",
    "train = \"/Users/devan/Desktop/AMLS_20-21_SN12345678/A1/data/train/\"# different machine \n",
    "test = \"/Users/devan/Desktop/AMLS_20-21_SN12345678/A1/data/test/\"\n",
    "validation = \"/Users/devan/Desktop/AMLS_20-21_SN12345678/A1/data/validation/\" # separarte paths are made to test, train and validation files\n",
    "\n",
    "os.makedirs(train + \"male/\") # separate male and female directories are made in the train ,test and validation directories\n",
    "os.makedirs(train + \"female/\")\n",
    "os.makedirs(test + \"male/\")\n",
    "os.makedirs(test + \"female/\")\n",
    "os.makedirs(validation + \"male/\")\n",
    "os.makedirs(validation + \"female/\")\n",
    "\n",
    "test_examples = train_examples = validation_examples = 0\n",
    "\n",
    "for line in open(\"/Users/devan/Desktop/AMLS_20-21_SN12345678/Datasets/celeba/labels.csv\").readlines()[1:]:\n",
    "    split_line = line.split(\",\")\n",
    "    img_file = split_line[1]     # The img file names are stored in 'img_file'\n",
    "    male_female = split_line[2]  # the labels for male and female are stored in male_female\n",
    "    \n",
    "    random_num = random.random() # random number generator\n",
    "\n",
    "    if random_num < 0.8:         # this stores 80% of data into the train folder\n",
    "        location = train\n",
    "        train_examples += 1\n",
    "\n",
    "    elif random_num < 0.9:       # this stores 10% of data into the validaton folder\n",
    "        location = validation\n",
    "        validation_examples += 1\n",
    "\n",
    "    else:\n",
    "        location = test          # this stores 10% of data into the test folder\n",
    "        test_examples += 1\n",
    "\n",
    "    if int(float(male_female)) == -1:\n",
    "        shutil.copy(\n",
    "            \"/Users/devan/Desktop/AMLS_20-21_SN12345678/Datasets/celeba/img/\" + img_file,\n",
    "            location + \"female/\" + img_file + \".jpg\", #if the img has a label -1 then store in female directory\n",
    "        )\n",
    "\n",
    "    elif int(float(male_female)) == 1:\n",
    "        shutil.copy(\n",
    "            \"/Users/devan/Desktop/AMLS_20-21_SN12345678/Datasets/celeba/img/\" + img_file,\n",
    "            location + \"male/\" + img_file + \".jpg\", #if the img has a label 1 then store in male directory\n",
    "        )\n",
    "\n",
    "print(f\"Number of training examples {train_examples}\")\n",
    "print(f\"Number of test examples {test_examples}\")\n",
    "print(f\"Number of validation examples {validation_examples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import roc_curve\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = 3955\n",
    "test_examples = 521\n",
    "validation_examples = 524\n",
    "img_height = img_width = 55\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(55,55,1)), #We dont flatten the input since we are using convolutional neural networks\n",
    "        layers.Conv2D(96, 5, strides = 1 , padding='same', activation = 'relu'),\n",
    "        layers.MaxPooling2D(pool_size=(3,3), strides = 2,padding='same'),\n",
    "        layers.Conv2D(256, 3, strides = 1 , padding='same', activation = 'relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2,2), strides = 2,padding='same'),\n",
    "        layers.Conv2D(384, 3, strides = 1 , padding='same', activation = 'relu'),\n",
    "        layers.Conv2D(256, 3, strides = 1 , padding='same', activation = 'relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1/255,\n",
    "    rotation_range = 15,\n",
    "    zoom_range = (0.95,0.95),\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    data_format = \"channels_last\",\n",
    "    dtype = tf.float32,\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255, dtype = tf.float32)\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255, dtype = tf.float32)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "\"/Users/devan/Desktop/AMLS_20-21_SN12345678/A1/data/train/\",\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size,\n",
    "color_mode = \"grayscale\",\n",
    "class_mode = \"binary\",   \n",
    "shuffle = True,\n",
    "seed = 123,\n",
    ")\n",
    "\n",
    "validation_gen = validation_datagen.flow_from_directory(\n",
    "\"/Users/devan/Desktop/AMLS_20-21_SN12345678/A1/data/validation/\",\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size,\n",
    "color_mode = \"grayscale\",\n",
    "class_mode = \"binary\",   \n",
    "shuffle = True,\n",
    "seed = 123,\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "\"/Users/devan/Desktop/AMLS_20-21_SN12345678/A1/data/test/\",\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size,\n",
    "color_mode = \"grayscale\",\n",
    "class_mode = \"binary\",   \n",
    "shuffle = True,\n",
    "seed = 123,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits = False),\n",
    "    optimizer = keras.optimizers.Adam(lr = 3e-4),\n",
    "    metrics = [\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=10,\n",
    "    batch_size = 10,\n",
    "    verbose=2,\n",
    "    steps_per_epoch=train_examples // batch_size,\n",
    "    validation_data=validation_gen,\n",
    "    validation_steps=validation_examples // batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(labels, data):\n",
    "    predictions = model.predict(data)\n",
    "    fp, tp, _ = roc_curve(labels,predictions)\n",
    "    \n",
    "    plt.plot(100*fp, 100*tp)\n",
    "    plt.xlabel(\"False\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.grid()\n",
    "    plt.show\n",
    "    \n",
    "test_labels = np.array([])\n",
    "num_batches = 0\n",
    "\n",
    "for _, y in test_gen:\n",
    "    test_labels = np.append(test_labels, y)\n",
    "    num_batches += 1\n",
    "    if num_batches == math.ceil(test_examples / batch_size):\n",
    "        break\n",
    "        \n",
    "plot_roc(test_labels, test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gen, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend((['Train', 'Test']), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend((['Train', 'Test']), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import landmarksGen as l2\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "\n",
    "    X, y = l2.extract_features_labels()\n",
    "    Y = np.array([y, -(y - 1)]).T\n",
    "    tr_X = X[:300]\n",
    "    tr_Y = Y[:300]\n",
    "    te_X = X[350:550]\n",
    "    te_Y = Y[350:550]\n",
    "    #print(y.shape)\n",
    "\n",
    "    return tr_X, tr_Y, te_X, te_Y, y, Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_X, tr_Y, te_X, te_Y, y, Y = get_data()\n",
    "print(te_X.shape)\n",
    "print(te_X.reshape((te_X.size//136, 68*2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn functions implementation\n",
    "def img_SVM(training_images, training_labels, test_images, test_labels):\n",
    "    classifier = svm.SVC(kernel = 'poly')\n",
    "    classifier.fit(training_images, training_labels)\n",
    "    pred = classifier.predict(training_images)\n",
    "    print(\"Accuracy:\", accuracy_score(training_labels, pred))\n",
    "\n",
    "   # print(pred)\n",
    "    return pred\n",
    "\n",
    "tr_X, tr_Y, te_X, te_Y, y, Y = get_data()\n",
    "pred=img_SVM(tr_X.reshape((tr_X.size//136, 68*2)), list(zip(*tr_Y))[0], te_X.reshape((te_X.size//136, 68*2)), list(zip(*te_Y))[0])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "directory = \"/Users/devan/Desktop/AMLS_20-21_SN12345678/Datasets/celeba/img/\" # this is doing the same as for gender, but for smiling or not smiling\n",
    "train = \"/Users/devan/Desktop/AMLS_20-21_SN12345678/A2/data1/train/\"\n",
    "test = \"/Users/devan/Desktop/AMLS_20-21_SN12345678/A2/data1/test/\"\n",
    "validation = \"/Users/devan/Desktop/AMLS_20-21_SN12345678/A2/data1/validation/\"\n",
    "\n",
    "os.makedirs(train + \"smiling/\")\n",
    "os.makedirs(train + \"n_smiling/\")\n",
    "os.makedirs(test + \"smiling/\")\n",
    "os.makedirs(test + \"n_smiling/\")\n",
    "os.makedirs(validation + \"smiling/\")\n",
    "os.makedirs(validation + \"n_smiling/\")\n",
    "\n",
    "test_examples = train_examples = validation_examples = 0\n",
    "\n",
    "for line in open(\"/Users/devan/Desktop/AMLS_20-21_SN12345678/Datasets/celeba/labels.csv\").readlines()[1:]:\n",
    "    split_line = line.split(\",\")\n",
    "    img_file = split_line[1]\n",
    "    s_ns = split_line[3]\n",
    "\n",
    "    random_num = random.random()\n",
    "\n",
    "    if random_num < 0.8:\n",
    "        location = train\n",
    "        train_examples += 1\n",
    "\n",
    "    elif random_num < 0.9:\n",
    "        location = validation\n",
    "        validation_examples += 1\n",
    "\n",
    "    else:\n",
    "        location = test\n",
    "        test_examples += 1\n",
    "\n",
    "    if int(float(s_ns)) == 1:\n",
    "        shutil.copy(\n",
    "            \"/Users/devan/Desktop/AMLS_20-21_SN12345678/Datasets/celeba/img/\" + img_file,\n",
    "            location + \"smiling/\" + img_file + \".jpg\",\n",
    "        )\n",
    "\n",
    "    elif int(float(s_ns)) == -1:\n",
    "        shutil.copy(\n",
    "            \"/Users/devan/Desktop/AMLS_20-21_SN12345678/Datasets/celeba/img/\" + img_file,\n",
    "            location + \"n_smiling/\" + img_file + \".jpg\",\n",
    "        )\n",
    "\n",
    "print(f\"Number of training examples {train_examples}\")\n",
    "print(f\"Number of test examples {test_examples}\")\n",
    "print(f\"Number of validation examples {validation_examples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import roc_curve\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = 3955\n",
    "test_examples = 521\n",
    "validation_examples = 524\n",
    "img_height = img_width = 90\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(90,90,1)), #We dont flatten the input since we are using convolutional neural networks\n",
    "        layers.Conv2D(32, 11, strides = 4 , padding='same', activation = 'relu'),\n",
    "        layers.MaxPooling2D(pool_size=(3,3), strides = 2,padding='same'),\n",
    "        layers.Conv2D(96, 5, strides = 1 , padding='same', activation = 'relu'),\n",
    "        layers.MaxPooling2D(pool_size=(3,3), strides = 2,padding='same'),\n",
    "        layers.Conv2D(128, 5, strides = 1 , padding='same', activation = 'relu'),\n",
    "        layers.Conv2D(96, 5, strides = 1 , padding='same', activation = 'relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(160, activation='sigmoid'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1/255,\n",
    "    rotation_range = 15,\n",
    "    zoom_range = (0.95,0.95),\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    data_format = \"channels_last\",\n",
    "    dtype = tf.float32,\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255, dtype = tf.float32)\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255, dtype = tf.float32)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "\"/Users/devan/Desktop/AMLS_20-21_SN12345678/A2/data1/train/\",\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size,\n",
    "color_mode = \"grayscale\",\n",
    "class_mode = \"binary\",   \n",
    "shuffle = True,\n",
    "seed = 123,\n",
    ")\n",
    "\n",
    "validation_gen = validation_datagen.flow_from_directory(\n",
    "\"/Users/devan/Desktop/AMLS_20-21_SN12345678/A2/data1/validation/\",\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size,\n",
    "color_mode = \"grayscale\",\n",
    "class_mode = \"binary\",   \n",
    "shuffle = True,\n",
    "seed = 123,\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "\"/Users/devan/Desktop/AMLS_20-21_SN12345678/A2/data1/test/\",\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size,\n",
    "color_mode = \"grayscale\",\n",
    "class_mode = \"binary\",   \n",
    "shuffle = True,\n",
    "seed = 123,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits = False),\n",
    "    optimizer = keras.optimizers.Adam(lr = 3e-4),\n",
    "    metrics = [\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "train_gen,\n",
    "epochs=10,\n",
    "verbose=2,\n",
    "steps_per_epoch=train_examples // batch_size,\n",
    "validation_data=validation_gen,\n",
    "validation_steps=validation_examples // batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(labels, data):\n",
    "    predictions = model.predict(data)\n",
    "    fp, tp, _ = roc_curve(labels,predictions)\n",
    "    \n",
    "    plt.plot(100*fp, 100*tp)\n",
    "    plt.xlabel(\"False\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.grid()\n",
    "    plt.show\n",
    "    \n",
    "test_labels = np.array([])\n",
    "num_batches = 0\n",
    "\n",
    "for _, y in test_gen:\n",
    "    test_labels = np.append(test_labels, y)\n",
    "    num_batches += 1\n",
    "    if num_batches == math.ceil(test_examples / batch_size):\n",
    "        break\n",
    "        \n",
    "plot_roc(test_labels, test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gen, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend((['Train', 'Test']), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend((['Train', 'Test']), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import landmarksEmot as l2\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "\n",
    "    X, y = l2.extract_features_labels()\n",
    "    Y = np.array([y, -(y - 1)]).T\n",
    "    tr_X = X[:300]\n",
    "    tr_Y = Y[:300]\n",
    "    te_X = X[350:550]\n",
    "    te_Y = Y[350:550]\n",
    "    #print(y.shape)\n",
    "\n",
    "    return tr_X, tr_Y, te_X, te_Y, y, Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_X, tr_Y, te_X, te_Y, y, Y = get_data()\n",
    "print(te_X.shape)\n",
    "print(te_X.reshape((te_X.size//136, 68*2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn functions implementation\n",
    "def img_SVM(training_images, training_labels, test_images, test_labels):\n",
    "    classifier = svm.SVC(kernel = 'poly')\n",
    "    classifier.fit(training_images, training_labels)\n",
    "    pred = classifier.predict(training_images)\n",
    "    print(\"Accuracy:\", accuracy_score(training_labels, pred))\n",
    "\n",
    "   # print(pred)\n",
    "    return pred\n",
    "\n",
    "tr_X, tr_Y, te_X, te_Y, y, Y = get_data()\n",
    "pred=img_SVM(tr_X.reshape((tr_X.size//136, 68*2)), list(zip(*tr_Y))[0], te_X.reshape((te_X.size//136, 68*2)), list(zip(*te_Y))[0])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FaceShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2grey\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"/Users/devan/Desktop/AMLS_20-21_SN12345678/Datasets/cartoon_set/labels.csv\", index_col=0)\n",
    "labels.head()\n",
    "sample_size = 150\n",
    "labels=labels.drop(labels.index[sample_size:])\n",
    "labels.drop(\"eye_color\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(row_id, root=\"/Users/devan/Desktop/AMLS_20-21_SN12345678/Datasets/cartoon_set/img\"):\n",
    "    \"\"\"\n",
    "    Converts an image number into the file path where the image is located, \n",
    "    opens the image, and returns the image as a numpy array.\n",
    "    \"\"\"\n",
    "    filename = \"{}.png\".format(row_id)\n",
    "    file_path = os.path.join(root, filename)\n",
    "    img = Image.open(file_path)\n",
    "    return np.array(img)\n",
    "\n",
    "shape1_row = labels[labels.face_shape == 4.0].index[0]\n",
    "plt.imshow(get_image(shape1_row))\n",
    "plt.show()\n",
    "shape2_row = labels[labels.face_shape == 3.0].index[0]\n",
    "plt.imshow(get_image(shape2_row))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a bombus image using our get_image function and bombus_row from the previous cell\n",
    "shape1 = get_image(shape1_row)\n",
    "shape2 = get_image(shape2_row)\n",
    "print('Color bombus image has shape: ', shape1)\n",
    "\n",
    "# convert the bombus image to greyscale\n",
    "grey_shape1 = rgb2grey(shape1)\n",
    "\n",
    "plt.imshow(grey_shape1, cmap=mpl.cm.gray)\n",
    "\n",
    "print('Greyscale bombus image has shape: ', grey_shape1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_features, hog_image = hog(grey_shape1,\n",
    "                              visualize=True,\n",
    "                              block_norm='L2-Hys',\n",
    "                              pixels_per_cell=(13, 13))\n",
    "\n",
    "plt.imshow(hog_image, cmap=mpl.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(img):\n",
    "    # flatten three channel color image\n",
    "    color_features = img.flatten()\n",
    "    # convert image to greyscale\n",
    "    grey_image = rgb2grey(img)\n",
    "    # get HOG features from greyscale image\n",
    "    hog_features = hog(grey_image, block_norm='L2-Hys', pixels_per_cell=(16, 16))\n",
    "    # combine color and hog features into a single array\n",
    "    flat_features = np.hstack(color_features)\n",
    "    return flat_features\n",
    "\n",
    "shape2_features = create_features(shape2)\n",
    "\n",
    "print(shape2_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(label_dataframe):\n",
    "    features_list = []\n",
    "    \n",
    "    for img_id in label_dataframe.index:\n",
    "        # load image\n",
    "        img = get_image(img_id)\n",
    "        # get features for image\n",
    "        image_features = create_features(img)\n",
    "        features_list.append(image_features)\n",
    "        \n",
    "    # convert list of arrays into a matrix\n",
    "    feature_matrix = np.array(features_list)\n",
    "    return feature_matrix\n",
    "\n",
    "# run create_feature_matrix on our dataframe of images\n",
    "feature_matrix = create_feature_matrix(labels)\n",
    "print(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shape of feature matrix\n",
    "print('Feature matrix shape is: ', feature_matrix.shape)\n",
    "\n",
    "# define standard scaler\n",
    "ss = StandardScaler()\n",
    "# run this on our feature matrix\n",
    "shape_stand = ss.fit_transform(feature_matrix)\n",
    "\n",
    "pca = PCA(n_components=500)\n",
    "# use fit_transform to run PCA on our standardized matrix\n",
    "shape_pca = ss.fit_transform(shape_stand)\n",
    "# look at new shape\n",
    "print('PCA matrix shape is: ', shape_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(shape_pca)\n",
    "y = pd.Series(labels.face_shape.values)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=.3,\n",
    "                                                    random_state=1234123)\n",
    "\n",
    "# look at the distrubution of labels in the train set\n",
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define support vector classifier\n",
    "svm = SVC(kernel='linear', probability=True, random_state=42)\n",
    "\n",
    "# fit model\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Model accuracy is: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators = 6)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities for X_test using predict_proba\n",
    "probabilities = svm.predict_proba(X_test)\n",
    "\n",
    "# select the probabilities for labels 0,1,2,3 and 4\n",
    "y_proba0 = probabilities[:, 0]\n",
    "y_proba1 = probabilities[:, 1]\n",
    "y_proba2 = probabilities[:, 2]\n",
    "y_proba3 = probabilities[:, 3]\n",
    "y_proba4 = probabilities[:, 4]\n",
    "# calculate false positive rate and true positive rate at different thresholds\n",
    "false_positive_rate0, true_positive_rate0, thresholds = roc_curve(y_test, y_proba0, pos_label=1)\n",
    "false_positive_rate1, true_positive_rate1, thresholds = roc_curve(y_test, y_proba1, pos_label=1)\n",
    "false_positive_rate2, true_positive_rate2, thresholds = roc_curve(y_test, y_proba2, pos_label=1)\n",
    "false_positive_rate3, true_positive_rate3, thresholds = roc_curve(y_test, y_proba3, pos_label=1)\n",
    "false_positive_rate4, true_positive_rate4, thresholds = roc_curve(y_test, y_proba4, pos_label=1)\n",
    "# calculate AUC\n",
    "roc_auc0 = auc(false_positive_rate0, true_positive_rate0)\n",
    "roc_auc1 = auc(false_positive_rate1, true_positive_rate1)\n",
    "roc_auc2 = auc(false_positive_rate2, true_positive_rate2)\n",
    "roc_auc3 = auc(false_positive_rate3, true_positive_rate3)\n",
    "roc_auc4 = auc(false_positive_rate4, true_positive_rate4)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "# plot the false positive rate on the x axis and the true positive rate on the y axis\n",
    "roc_plot0 = plt.plot(false_positive_rate0,\n",
    "                    true_positive_rate0,\n",
    "                    label='AUC1 = {:0.2f}'.format(roc_auc0))\n",
    "roc_plot1 = plt.plot(false_positive_rate1,\n",
    "                    true_positive_rate1,\n",
    "                    label='AUC2 = {:0.2f}'.format(roc_auc1))\n",
    "roc_plot2 = plt.plot(false_positive_rate2,\n",
    "                    true_positive_rate2,\n",
    "                    label='AUC3 = {:0.2f}'.format(roc_auc2))\n",
    "roc_plot3 = plt.plot(false_positive_rate3,\n",
    "                    true_positive_rate3,\n",
    "                    label='AUC4 = {:0.2f}'.format(roc_auc3))\n",
    "roc_plot4 = plt.plot(false_positive_rate4,\n",
    "                    true_positive_rate4,\n",
    "                    label='AUC5 = {:0.2f}'.format(roc_auc4))\n",
    "plt.legend(loc=0)\n",
    "plt.plot([0,1], [0,1], ls='--')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eye Colour Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/Users/devan/Desktop/AMLS_20-21_SN12345678/Datasets/cartoon_set/labels.csv\")\n",
    "train.columns\n",
    "train.rename( columns={'Unnamed: 0':'Id'}, inplace=True )\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = []\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    img = image.load_img(\"/Users/devan/Desktop/AMLS_20-21_SN12345678/Datasets/cartoon_set/img/\"+str(train['Id'][i])+'.png',target_size=(50,50,3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    train_image.append(img)\n",
    "X = np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape\n",
    "X1 = X[:500]\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X1[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(train)\n",
    "y1 = y[:500]\n",
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train.reshape(450,3*50*50)\n",
    "X_test1 = X_test.reshape(50,3*50*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define support vector classifier\n",
    "svm = SVC(kernel='poly', probability=True, random_state=42)\n",
    "\n",
    "# fit model\n",
    "svm.fit(X_train1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions\n",
    "y_pred = svm.predict(X_test1)\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Model accuracy is: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators = 40)\n",
    "model.fit(X_train1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test1, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
